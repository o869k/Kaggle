pb <- pbeta(0.75)
pb <- pbeta(0.75,1)
pb <- pbeta(0.75,2,1)
pb
?pbinom
pbinom(7,8,0.5)
pbinom(6,8,0.5)
pbinom(7,8,0.5,lowr.tail=FALSE)
pbinom(7,8,0.5,lower.tail=FALSE)
pbinom(6,8,0.5,lower.tail=FALSE)
pbinom(5,8,0.5,lower.tail=FALSE)
pbinom(8,8,0.5,lower.tail=FALSE)
pbinom(7,8,0.5,lower.tail=FALSE)
qnorm(0.95)
ppois(40,9*5)
?sample
sample(0:1,1000)
sample(0:1,1000,replace=TRUE)
sample(0:1,1000,replace=TRUE)/(1:n)
sample(0:1,1000,replace=TRUE)/(1:1000)
cumsum(sample(0:1,1000,replace=TRUE))/(1:1000)
plot(cumsum(sample(0:1,1000,replace=TRUE))/(1:1000))
library(UsingR)
download.packages(UsingR)
download.packages("UsingR")
download.packages(date)
download.packages("date"")
download.packages("date")
setwd("~/")
download.packages("date")
file.info(x)
file.info(
)
install.packages(c("labeling", "psych"))
download.packages("date")
?destdir
?destdir()
?file.info(x)
download.packages("date.R")
download.packages("date.R",destdir=C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages)
download.packages("date.R",destdir="C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages")
download.packages(date.R,destdir="C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages")
download.packages("date.R",destdir="C:/Users\user\AppData/Local/Temp/RtmporU4ma/downloaded_packages")
download.packages("date.R",destdir="/Users\user\AppData/Local/Temp/RtmporU4ma/downloaded_packages")
download.packages("date.R",destdir=.)
download.packages("date.R",destdir=NULL)
download.packages(date.R,destdir=NULL)
download.packages(date.R)
library("ggplot2", lib.loc="~/R/win-library/3.1")
install.packages("date")
install.packages(UsingR)
install.packages("UsingR")
data(fater.son)
library(UsingR)
data(father.son)
View(father.son)
summary(father.son)
x <- father.son$sheight
mean(x)
mean(x)+c(-1,1)*qnorm(0.975)*sd(x)/sqrt(length(x))
mean(x)+c(-1,1)*qnorm(0.95)*sd(x)/sqrt(length(x))
x <- father.son$fheight
mean(x)+c(-1,1)*qnorm(0.95)*sd(x)/sqrt(length(x))
poisson.test(10)
poisson.test(10)$conf
poisson.test(10,T = 1)$conf
poisson.test(60,T = 1)$conf
poisson.test(10,T = 60)$conf
poisson.test(10,T = 1)$conf
poisson.test(0.1,T = 1)$conf
poisson.test(6,T = 1)$conf
poisson.test(10,T = 10)$conf
poisson.test(10,T = 60)$conf
poisson.test(10,T = 6)$conf
poisson.test(10,T = 3)$conf
poisson.test(10,T = 2)$conf
poisson.test(10,T = 1)$conf
poisson.test(20,T = 1)$conf
poisson.test(5,T = 1)$conf
install.packages(ISLR)
install.packages("ISLR")
library("ggplot2", lib.loc="~/R/win-library/3.1")
library(ISLR); library(ggplot2)
data(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- spam[inTrain,]
testSet <- spam[-inTrain,]
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
library("caret") # a ML models package
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
featurePlot(x=trainSet[,c("age","jobclass")],y=trainSet$wage,plot="pairs") #present the wage date vs. age & jobclass
qplot(wage,color=eductaion,data=trainSet,geom="density") # a density plot of wage vs. education
qplot(wage,color=education,data=trainSet,geom="density") # a density plot of wage vs. education
library(kernlab); library("e1071"); data(spam)
library(kernlab); library("e1071"); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75,list=F) #create 75% train set of data
trainSet <- spam[inTrain,]
testSet <- spam[-inTrain,]
folds1 <- createFolds(y=trainSet$type,k=10,list=TRUE,returnTrain = TRUE)#create a 10 kfold cross validation on train set for features optimization
folds2 <- createResample(y=spam$type,times=10,list=TRUE)#create a 10 kfold resampling on data with replacement
#sapply(folds1,length) #size of folds
modelFit <- train(type ~ .,data=trainSet,method="glm") #train a glm algo on data
modelFit$finalModel #best fitted model
predictions <- predict(modelFit,newdata=testSet) #run the fitted model on test data
confusionMatrix(predictions,testSet$type) #creates a hypotesis tableconfusion matrix
#Standardizing the features
preObj <- preProcess(trainSet[,-58],method==c("center","scale"))
trainSetStandart <- predict(preObj,trainSet[,-58])$capitalAAve
preObj <- preProcess(trainSet[,-58],method=c("center","scale"))
trainSetStandart <- predict(preObj,trainSet[,-58])$capitalAAve
preObj <- preProcess(trainSet[,-58],method=c("center","scale","knnImpute"))
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
dummies <- dummyVars(wage ~ jobclass,data=trainSet)
head(dummies)
head(dummies,newdata=trainSet)
head(predict(dummies,newdata=trainSet))
nsv <- nearZeroVar(trainSet,saveMetrics = T) #check for zero covariates
nsv
#Initialization
{
sessionInfo() #system performance
gc() #clear unsued memory
rm(list=ls()) # clear workspace
mainDir <- "C:/Users/user/Documents"
setwd(mainDir)
set.seed(1234) #setting seed for comparison
memory.limit(size=3000)
library(h2o); library(e1071)
}
data <- read.csv("Book1.csv",header = F)
View(data)
hist(data$V2)
hist(data$V1)
hist(data$V3)
hist(data$V1,breaks = 30)
hist(data$V3,breaks = 10)
hist(data$V2,breaks = 12)
hist(data$V2,breaks = 13)
data <- read.csv("Book1.csv",header = F)
View(data)
data <- read.csv("Book1.csv",header = F)
View(data)
data <- read.csv("Book1.csv",header = T)
View(data)
hist(data$name)
table(data$month)
table(data$day)
table(data$name)
View(data)
table(sort(data$name))
hist(data$month,breaks = 12)
source('~/R/otto/otto_preprocess.R', echo=TRUE)
#Initialization
{
sessionInfo() #system performance
gc() #clear unsued memory
rm(list=ls()) # clear workspace
mainDir <- "C:/Users/user/Documents/R/otto"
setwd(mainDir)
set.seed(1234) #setting seed for comparison
library(e1071); library(FSelector);
library(foreach); library(doParallel);
library(ggplot2); library(h2o);
}
#Initialization
{
sessionInfo() #system performance
gc() #clear unsued memory
rm(list=ls()) # clear workspace
mainDir <- "C:/Users/user/Documents/R/otto"
setwd(mainDir)
set.seed(1234) #setting seed for comparison
library(foreach); library(doParallel);
library(ggplot2); library(randomForest);
}
#Read Data
{
train <- read.csv("trainNEW.csv")
test <- read.csv("testNEW.csv")
Submission <- read.csv("sampleSubmission.csv")
M <- ncol(train) #Number of features per sample (columns)
N <- nrow(train) #Number of features per sample (columns)
L <- nlevels(train$target) #Number of features per sample (columns)
Ntest <- nrow(test) #Number of features per sample (columns)
}
str(train)
table(train$target)
#Function for evaluation
Kappa_eval <- function(true.y, pred) {
return(1 - classAgreement(table(pred, true.y))$kappa)
}
LogLoss <- function(true.y, pred, eps=0.00001) {
pred <- pmin(pmax(pred, eps), 1-eps)
-(log(pred[true.y]))
}
#Histograms of each feature - before transformations
for (i in seq(from=2,to=(M-1),by=4)) {
par(mfrow=c(2,2))
hist((train[train$target=="Class_1",i]),100,main = (i))
hist((train[train$target=="Class_1",i+1]),100,main = (i+1))
hist((train[train$target=="Class_1",i+2]),100,main = (i+2))
hist((train[train$target=="Class_1",i+3]),100,main = (i+3))
par(mfrow=c(1,1))
}
#Present the counts per example (scaled)
plot(2:(M-1),train[1,2:(M-1)],type="s")
#Present the counts of events per class (scaled)
{
par(mfrow=c(3,3))
plot(2:(M-1),colSums(train[train$target=="Class_1",2:(M-1)]),type="s",main = 1)
plot(2:(M-1),colSums(train[train$target=="Class_2",2:(M-1)]),type="s",main = 2)
plot(2:(M-1),colSums(train[train$target=="Class_3",2:(M-1)]),type="s",main = 3)
plot(2:(M-1),colSums(train[train$target=="Class_4",2:(M-1)]),type="s",main = 4)
plot(2:(M-1),colSums(train[train$target=="Class_5",2:(M-1)]),type="s",main = 5)
plot(2:(M-1),colSums(train[train$target=="Class_6",2:(M-1)]),type="s",main = 6)
plot(2:(M-1),colSums(train[train$target=="Class_7",2:(M-1)]),type="s",main = 7)
plot(2:(M-1),colSums(train[train$target=="Class_8",2:(M-1)]),type="s",main = 8)
plot(2:(M-1),colSums(train[train$target=="Class_9",2:(M-1)]),type="s",main = 9)
par(mfrow=c(1,1))}
#Present the counts of events per class (scaled)
{
par(mfrow=c(3,3))
plot(2:(M-1),colSums(train[train$target=="Class_1",2:(M-1)]),type="s",main = 1)
plot(2:(M-1),colSums(train[train$target=="Class_2",2:(M-1)]),type="s",main = 2)
plot(2:(M-1),colSums(train[train$target=="Class_3",2:(M-1)]),type="s",main = 3)
plot(2:(M-1),colSums(train[train$target=="Class_4",2:(M-1)]),type="s",main = 4)
plot(2:(M-1),colSums(train[train$target=="Class_5",2:(M-1)]),type="s",main = 5)
plot(2:(M-1),colSums(train[train$target=="Class_6",2:(M-1)]),type="s",main = 6)
plot(2:(M-1),colSums(train[train$target=="Class_7",2:(M-1)]),type="s",main = 7)
plot(2:(M-1),colSums(train[train$target=="Class_8",2:(M-1)]),type="s",main = 8)
plot(2:(M-1),colSums(train[train$target=="Class_9",2:(M-1)]),type="s",main = 9)
par(mfrow=c(1,1))}
#Divide to train and eval - multifolds & other initializations
{
K <- 3 #number of folds (70-30)
Times <- 2 #number of resamples (5)
folds <- createMultiFolds(train$target,k=K,times = Times)
M <- ncol(train)
N <- nrow(train) #Number of real samples (rows)
ntrees <- c(10) # vector of trees, it is then multiplied by number of cpus (4)
train_score_ntrees <- rep(0,length(ntrees))
eval_score_ntrees <- rep(0,length(ntrees))
}
library(fpp); library(UsingR)
library(caret); library(kernlab)
library(foreach); library(doParallel)
library(ggplot2); library(ROCR)
library(randomForest); library(date)
library(data.table); library(bit64)
library(matrixStats); library(e1071)
library(FSelector); library(lubridate)
#Divide to train and eval - multifolds & other initializations
{
K <- 3 #number of folds (70-30)
Times <- 2 #number of resamples (5)
folds <- createMultiFolds(train$target,k=K,times = Times)
M <- ncol(train)
N <- nrow(train) #Number of real samples (rows)
ntrees <- c(10) # vector of trees, it is then multiplied by number of cpus (4)
train_score_ntrees <- rep(0,length(ntrees))
eval_score_ntrees <- rep(0,length(ntrees))
}
folds[[1]]
train$target[folds[[1]]]
table(train$target[folds[[1]]])
train_Score <- rep(0,K*Times)
eval_Score <- rep(0,K*Times)
i <- 1
j<-1
cl<-makeCluster(4)
registerDoParallel(cl)
model_RF <- foreach(ntree=rep(ntrees[j],4), .combine=combine, .verbose=T, .packages='randomForest') %dopar% {
randomForest(y=train$target[c(folds[[i]])],x=train[c(folds[[i]]),],xtest = train[c(folds[[i]]),],
ytest = train$outcome[c(folds[[i]])],importance = T,ntree=ntree,do.trace=T,keep.forest=T)}
stopCluster(cl)
train$target[folds[[i]]]
gc()
train$outcome[-folds[[i]]]
folds[[i]]
c(folds[[i]])
train$outcome[-c(folds[[i]])]
train$outcome
train$target
train$target[-c(folds[[i]])]
train$target[-folds[[i]]]
table(train$target[-folds[[i]]])
stopCluster(cl)
cl<-makeCluster(4)
registerDoParallel(cl)
model_RF <- foreach(ntree=rep(ntrees[j],4), .combine=combine, .verbose=T, .packages='randomForest') %dopar% {
randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=ntree,do.trace=T,keep.forest=T)}
stopCluster(cl)
ntrees[j]
ntrees <- c(1) # vector of trees, it is then multiplied by number of cpus (4)
summary(train)
cl<-makeCluster(4)
registerDoParallel(cl)
model_RF <- foreach(ntree=rep(ntrees[j],4), .combine=combine, .verbose=T, .packages='randomForest') %dopar% {
randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=ntree,keep.forest=T)}
stopCluster(cl)
#Initialization
{
sessionInfo() #system performance
gc() #clear unsued memory
rm(list=ls()) # clear workspace
mainDir <- "C:/Users/user/Documents/R/otto"
setwd(mainDir)
set.seed(1234) #setting seed for comparison
library(fpp); library(UsingR)
library(caret); library(kernlab)
library(foreach); library(doParallel)
library(ggplot2); library(ROCR)
library(randomForest); library(date)
library(data.table); library(bit64)
library(matrixStats); library(e1071)
library(FSelector); library(lubridate)
}
#Read Data
{
train <- read.csv("trainNEW.csv")
test <- read.csv("testNEW.csv")
Submission <- read.csv("sampleSubmission.csv")
M <- ncol(train) #Number of features per sample (columns)
N <- nrow(train) #Number of features per sample (columns)
L <- nlevels(train$target) #Number of features per sample (columns)
Ntest <- nrow(test) #Number of features per sample (columns)
}
#Function for evaluation
Kappa_eval <- function(true.y, pred) {
return(1 - classAgreement(table(pred, true.y))$kappa)
}
LogLoss <- function(true.y, pred, eps=0.00001) {
pred <- pmin(pmax(pred, eps), 1-eps)
-(log(pred[true.y]))
}
#Divide to train and eval - multifolds & other initializations
{
K <- 3 #number of folds (70-30)
Times <- 2 #number of resamples (5)
folds <- createMultiFolds(train$target,k=K,times = Times)
M <- ncol(train)
N <- nrow(train) #Number of real samples (rows)
ntrees <- c(1) # vector of trees, it is then multiplied by number of cpus (4)
train_score_ntrees <- rep(0,length(ntrees))
eval_score_ntrees <- rep(0,length(ntrees))
}
j <- 1
i <- 1
train_Score <- rep(0,K*Times)
eval_Score <- rep(0,K*Times)
cl<-makeCluster(4)
registerDoParallel(cl)
model_RF <- foreach(ntree=rep(ntrees[j],4), .combine=combine, .verbose=T, .packages='randomForest') %dopar% {
randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=ntree,keep.forest=T)}
stopCluster(cl)
model_RF <-             randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=ntree,keep.forest=T)
model_RF <-             randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=1,keep.forest=T)
model_RF$predicted
table(model_RF$predicted)
table(model_RF$
model_RF$err.rate
model_RF$confusion
classAgreement(model_RF$confusion)$kappa
classAgreement(model_RF$test$confusion)$kappa
classAgreement(model_RF$test$confusion)$kappa
model_RF$test$err.rate
model_RF$err.rate
model_RF$inbag
model_RF$votes
model_RF$votes[,1]
train_predictions <- predict(model_RF,train[folds[[i]],-M],type="prob")
train_predictions
sum <- 0
train$target[l]
l <-
1
train$target[l]
as.numeric(train$target[l])
as.numeric(train_predictions[l,]
)
as.numeric(train_predictions[l,as.numeric(train$target[l])])
LogLoss(as.numeric(train$target[l]),as.numeric(train_predictions[l,as.numeric(train$target[l])]))
for (l in 1:nrow(train_predictions))
{
sum <- sum + LogLoss(as.numeric(train$target)[l],as.numeric(train_predictions[l,]))
}
sum <- 0
classAgreement(model_RF$confusion)$kappa
for (l in 1:nrow(train_predictions))
{
sum <- sum + LogLoss(as.numeric(train$target[l]),as.numeric(train_predictions[l,as.numeric(train$target[l])]))
}
train_predictions
train$target[folds[[i]]]
train$target[folds[[i]]][l]
ll_train <- sum/nrow(train_predictions)
ll_train
sum
eval_predictions <- predict(model_RF,train[-folds[[i]],],"prob")
eval_predictions
sum <- 0
for (l in 1:nrow(eval_predictions))
{
sum <- sum + LogLoss(as.numeric(train$target[-folds[[i]]][l]),as.numeric(eval_predictions[l,as.numeric(train$target[l])]))
}
sum
model_RF$votes[1,]
as.numeric(train$target[-folds[[i]]][l])
eval_predictions[l,as.numeric(train$target[-folds[[i]]][l])]
as.numeric(train$target[-folds[[i]]][l])
as.numeric(train$target[folds[[i]]][l])
as.numeric(train$target[-folds[[i]]][l])
as.numeric(eval_predictions[l,]
)
as.numeric(model_RF$votes[l,])
as.numeric(model_RF$votes[l,])
model_RF$votes[l,])
model_RF$votes[l,]
model_RF <-             randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=10,keep.forest=T)
sum <- 0
l <- 1
as.numeric(train$target[folds[[i]]][l])
as.numeric(model_RF$votes[l,])
{
sum <- 0
for (l in 1:nrow(train_predictions))
{
sum <- sum + LogLoss(as.numeric(train$target[folds[[i]]][l]),as.numeric(model_RF$votes[l,]))
}
ll_OOB[i] <- sum/nrow(train_predictions)
classAgreement(model_RF$confusion)$kappa
model_RF$err.rate
}
ll_OOB <- rep(0,K*Times)
ll_OOB[i] <- sum/nrow(train_predictions)
sum/nrow(train_predictions)
as.numeric(model_RF$votes[l,])
train$target[folds[[i]]][l])
as.numeric(train$target[folds[[i]]][l])
LogLoss(as.numeric(train$target[folds[[i]]][l]),as.numeric(model_RF$votes[l,]))
nrow(train_predictions)
classAgreement(model_RF$confusion)$kappa
model_RF$err.rate
train_predictions <- predict(model_RF,train[folds[[i]],-M],type="prob")
classAgreement(model_RF$test$confusion)$kappa
model_RF$test$err.rate
for (l in 1:nrow(train_predictions))
{
sum <- sum + LogLoss(as.numeric(train$target[folds[[i]]][l]),as.numeric(train_predictions[l,]))
}
sum
LogLoss(as.numeric(train$target[folds[[i]]][l]),as.numeric(train_predictions[l,]))
eval_predictions <- predict(model_RF,train[-folds[[i]],],"prob")
sum <- 0
for (l in 1:nrow(eval_predictions))
{
sum <- sum + LogLoss(as.numeric(train$target[-folds[[i]]][l]),as.numeric(eval_predictions[l,]))
}
ll_eval[i] <- sum/nrow(eval_predictions)
ll_eval <- rep(0,K*Times)
ll_train <- rep(0,K*Times)
sum
ll_eval[i] <- sum/nrow(eval_predictions)
ll_eval[i]
model_RF <-             randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=100,keep.forest=T)
gc()
rm(Submission,eval_predictions,train_predictions,train_Score,train_score_ntrees,eval_Score,eval_score_ntrees)
gc()
model_RF <-             randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=100,keep.forest=T)
ntrees <- c(10) # vector of trees, it is then multiplied by number of cpus (4)
cl<-makeCluster(4)
registerDoParallel(cl)
model_RF <- foreach(ntree=rep(ntrees[j],4), .combine=combine, .verbose=T, .packages='randomForest') %dopar% {
randomForest(y=train$target[folds[[i]]],x=train[folds[[i]],-M],xtest = train[folds[[i]],-M],
ytest = train$target[folds[[i]]],importance = T,ntree=ntree,keep.forest=T)}
stopCluster(cl)

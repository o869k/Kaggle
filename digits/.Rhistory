pb <- pbeta(0.75)
pb <- pbeta(0.75,1)
pb <- pbeta(0.75,2,1)
pb
?pbinom
pbinom(7,8,0.5)
pbinom(6,8,0.5)
pbinom(7,8,0.5,lowr.tail=FALSE)
pbinom(7,8,0.5,lower.tail=FALSE)
pbinom(6,8,0.5,lower.tail=FALSE)
pbinom(5,8,0.5,lower.tail=FALSE)
pbinom(8,8,0.5,lower.tail=FALSE)
pbinom(7,8,0.5,lower.tail=FALSE)
qnorm(0.95)
ppois(40,9*5)
?sample
sample(0:1,1000)
sample(0:1,1000,replace=TRUE)
sample(0:1,1000,replace=TRUE)/(1:n)
sample(0:1,1000,replace=TRUE)/(1:1000)
cumsum(sample(0:1,1000,replace=TRUE))/(1:1000)
plot(cumsum(sample(0:1,1000,replace=TRUE))/(1:1000))
library(UsingR)
download.packages(UsingR)
download.packages("UsingR")
download.packages(date)
download.packages("date"")
download.packages("date")
setwd("~/")
download.packages("date")
file.info(x)
file.info(
)
install.packages(c("labeling", "psych"))
download.packages("date")
?destdir
?destdir()
?file.info(x)
download.packages("date.R")
download.packages("date.R",destdir=C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages)
download.packages("date.R",destdir="C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages")
download.packages(date.R,destdir="C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages")
download.packages("date.R",destdir="C:/Users\user\AppData/Local/Temp/RtmporU4ma/downloaded_packages")
download.packages("date.R",destdir="/Users\user\AppData/Local/Temp/RtmporU4ma/downloaded_packages")
download.packages("date.R",destdir=.)
download.packages("date.R",destdir=NULL)
download.packages(date.R,destdir=NULL)
download.packages(date.R)
library("ggplot2", lib.loc="~/R/win-library/3.1")
install.packages("date")
install.packages(UsingR)
install.packages("UsingR")
data(fater.son)
library(UsingR)
data(father.son)
View(father.son)
summary(father.son)
x <- father.son$sheight
mean(x)
mean(x)+c(-1,1)*qnorm(0.975)*sd(x)/sqrt(length(x))
mean(x)+c(-1,1)*qnorm(0.95)*sd(x)/sqrt(length(x))
x <- father.son$fheight
mean(x)+c(-1,1)*qnorm(0.95)*sd(x)/sqrt(length(x))
poisson.test(10)
poisson.test(10)$conf
poisson.test(10,T = 1)$conf
poisson.test(60,T = 1)$conf
poisson.test(10,T = 60)$conf
poisson.test(10,T = 1)$conf
poisson.test(0.1,T = 1)$conf
poisson.test(6,T = 1)$conf
poisson.test(10,T = 10)$conf
poisson.test(10,T = 60)$conf
poisson.test(10,T = 6)$conf
poisson.test(10,T = 3)$conf
poisson.test(10,T = 2)$conf
poisson.test(10,T = 1)$conf
poisson.test(20,T = 1)$conf
poisson.test(5,T = 1)$conf
install.packages(ISLR)
install.packages("ISLR")
library("ggplot2", lib.loc="~/R/win-library/3.1")
library(ISLR); library(ggplot2)
data(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- spam[inTrain,]
testSet <- spam[-inTrain,]
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
library("caret") # a ML models package
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
featurePlot(x=trainSet[,c("age","jobclass")],y=trainSet$wage,plot="pairs") #present the wage date vs. age & jobclass
qplot(wage,color=eductaion,data=trainSet,geom="density") # a density plot of wage vs. education
qplot(wage,color=education,data=trainSet,geom="density") # a density plot of wage vs. education
library(kernlab); library("e1071"); data(spam)
library(kernlab); library("e1071"); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75,list=F) #create 75% train set of data
trainSet <- spam[inTrain,]
testSet <- spam[-inTrain,]
folds1 <- createFolds(y=trainSet$type,k=10,list=TRUE,returnTrain = TRUE)#create a 10 kfold cross validation on train set for features optimization
folds2 <- createResample(y=spam$type,times=10,list=TRUE)#create a 10 kfold resampling on data with replacement
#sapply(folds1,length) #size of folds
modelFit <- train(type ~ .,data=trainSet,method="glm") #train a glm algo on data
modelFit$finalModel #best fitted model
predictions <- predict(modelFit,newdata=testSet) #run the fitted model on test data
confusionMatrix(predictions,testSet$type) #creates a hypotesis tableconfusion matrix
#Standardizing the features
preObj <- preProcess(trainSet[,-58],method==c("center","scale"))
trainSetStandart <- predict(preObj,trainSet[,-58])$capitalAAve
preObj <- preProcess(trainSet[,-58],method=c("center","scale"))
trainSetStandart <- predict(preObj,trainSet[,-58])$capitalAAve
preObj <- preProcess(trainSet[,-58],method=c("center","scale","knnImpute"))
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
dummies <- dummyVars(wage ~ jobclass,data=trainSet)
head(dummies)
head(dummies,newdata=trainSet)
head(predict(dummies,newdata=trainSet))
nsv <- nearZeroVar(trainSet,saveMetrics = T) #check for zero covariates
nsv
#Initialization
{
sessionInfo() #system performance
gc() #clear unsued memory
rm(list=ls()) # clear workspace
mainDir <- "C:/Users/user/Documents"
setwd(mainDir)
set.seed(1234) #setting seed for comparison
memory.limit(size=3000)
library(h2o); library(e1071)
}
data <- read.csv("Book1.csv",header = F)
View(data)
hist(data$V2)
hist(data$V1)
hist(data$V3)
hist(data$V1,breaks = 30)
hist(data$V3,breaks = 10)
hist(data$V2,breaks = 12)
hist(data$V2,breaks = 13)
data <- read.csv("Book1.csv",header = F)
View(data)
data <- read.csv("Book1.csv",header = F)
View(data)
data <- read.csv("Book1.csv",header = T)
View(data)
hist(data$name)
table(data$month)
table(data$day)
table(data$name)
View(data)
table(sort(data$name))
hist(data$month,breaks = 12)
#Initialization
{
sessionInfo() #system performance
gc() #clear unsued memory
rm(list=ls()) # clear workspace
setwd("C:/Users/user/Documents/R/digits")
set.seed(1234) #setting seed for comparison
library(date); library(fpp)
library(ff); library(ggplot2)
library(caret); library(kernlab)
library(e1071); library(UsingR)
library(deepnet); library(FNN)
library(h2o);
}
#Read Data & Preallocation:
{
trainSet <- read.csv("train.csv")
N <- nrow(trainSet)  #Number of train samples
testSet <- read.csv("test.csv")
Nt <- nrow(testSet) #Number of test samples
M <- ncol(trainSet)-1 #Number of pixles per sample
}
#Preprocess: displaying a number
{
pic_col <- as.numeric(trainSet[4,1:M])
pic <- matrix(rev(pic_col),nrow=sqrt(M))
image(pic,col=gray((0:255/255))) #show the image
}
#Start a local cluster & load model
{
#h2o.shutdown(localH2O)
localH2O <- h2o.init(nthreads = -1,ip = "localhost", port = 54321, startH2O = TRUE) #start h2o connection
#model <- h2o.loadModel(localH2O, "./mymodel")
}
train_hex <- as.h2o(localH2O, trainSet, key = 'trainSet')
test_hex <- as.h2o(localH2O, testSet, key = 'testSet')
h2o.shutdown(localH2O)

parameter <- c(1,2,3,4,5,6,7,8,9)
mean_rmse_eval <- rep(0,length(parameter))
sd_rmse_eval <- rep(0,length(parameter))
diff_rmse_eval_rmse_train <- rep(0,length(parameter))
for (j in 1:length(parameter))
{
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
model <- nnet(revenue~.,data = train[c(folds[[i]]),], size = parameter[j], maxit = 1000)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rm(model,prediction)
}
mean_rmse_eval[j] <- mean(rmse_eval)
sd_rmse_eval[j] <- sd(rmse_eval)
diff_rmse_eval_rmse_train[j] <- abs(mean(rmse_eval)-mean(rmse_train))
cat('Current mean EVAL RMSE:' ,mean_rmse_eval[j], "\n")
cat('Current sd EVAL RMSE:' ,sd_rmse_eval[j], "\n")
cat('Current difference EVAL RMSE and TRAIN RMSE:' ,diff_rmse_eval_rmse_train[j], "\n")
}
}
model <- nnet(revenue~.,data = train[c(folds[[i]]),], size = parameter[j],decay = 0.1, maxit = 1000)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rmse_train
rmse_eval
model <- nnet(revenue~.,data = train[c(folds[[i]]),], size = parameter[j],decay = 0.2, maxit = 10000)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rmse_train
rmse_eval
model <- train(revenue~., data = train[c(folds[[i]]),], method = "neuralnet", algorithm = 'backprop', learningrate = 0.25, hidden = 3, trControl = ctrl, linout = TRUE)
model <- train(revenue~., data = train[c(folds[[i]]),], method = "neuralnet", algorithm = 'backprop', learningrate = 0.25, hidden = 3, trControl = ctrl, linout = TRUE)
model <- train(revenue~., data = train[c(folds[[i]]),], method = "neuralnet", algorithm = 'backprop', learningrate = 0.25, hidden = 3)
?neuralnet
model <- neuralnet(revenue~., data = train[c(folds[[i]]),], algorithm = 'backprop', learningrate = 0.25, hidden = 3)
model <- neuralnet(formula = revenue ~ .,data = train[c(folds[[i]]),], algorithm = 'backprop', learningrate = 0.25, hidden = 3)
model <- neuralnet(revenue~.,data = train[c(folds[[i]]),], algorithm = 'backprop', learningrate = 0.25, hidden = 3)
train[c(folds[[i]]),]
model <- neuralnet(revenue~.,data = train[c(folds[[i]]),])
model <- neuralnet(features_bf,data = train[c(folds[[i]]),])
model <- neuralnet(features_bs,data = train[c(folds[[i]]),])
model <- svm(revenue~., data = train[c(folds[[i]]),], kernel="radial", gamma=0.1, cost=0.1)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rmse_train
rmse_eval
tuned <- tune.svm(revenue~., data = train, gamma = 10^(-6:-1), cost = 10^(-1:4),kernel="radial")
tuned
tuned$performances
?tuned
?tune.svm
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
model <- svm(revenue~., data = train[c(folds[[i]]),], kernel="radial", gamma=tuned$best.parameters$gamma, cost=tuned$best.parameters$cost)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rm(model,prediction)
}
mean_rmse_eval[j] <- mean(rmse_eval)
sd_rmse_eval[j] <- sd(rmse_eval)
diff_rmse_eval_rmse_train[j] <- abs(mean(rmse_eval)-mean(rmse_train))
cat('Current mean EVAL RMSE:' ,mean_rmse_eval[j], "\n")
cat('Current sd EVAL RMSE:' ,sd_rmse_eval[j], "\n")
cat('Current difference EVAL RMSE and TRAIN RMSE:' ,diff_rmse_eval_rmse_train[j], "\n")
mean_rmse_eval
sd_rmse_eval
diff_rmse_eval_rmse_train
rmse_eval
rmse_train
ntree <- 25
#function for feature selection evaluation on RF
evaluator_model <- function(subset)
{
cat('Current Subset:' ,subset, "\n")
ntree <- 25
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
model <- randomForest(as.simple.formula(subset,"revenue"),data = train[c(folds[[i]]),], importance = T,ntree=ntree)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rm(model,prediction)
}
cat('Current mean EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('Current sd EVAL RMSE:' ,sd(rmse_eval), "\n")
cat('Current difference EVAL RMSE and TRAIN RMSE:' ,abs(mean(rmse_eval)-mean(rmse_train)), "\n")
#return(-mean(rmse_eval)) #optimize on minimum mean RMSE
#return(-sd(rmse_eval)) #optimize on minimum sd RMSE
#return(-abs(mean(rmse_eval)-mean(rmse_train))) #optimize on RMSE difference between eval and train
return(-log10(sd(rmse_eval))*log10(mean(rmse_eval))*log10(abs(mean(rmse_eval)-mean(rmse_train)))) #optimize on all metrics
}
#BFS Feature Selection only
{
subset_bfs <- NULL
subset_bfs <- best.first.search(sample(names(train[,-M])),evaluator_model)
features_bfs <- as.simple.formula(subset_bfs, "revenue")
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times)) {
model <- randomForest(features_bfs,data = train[c(folds[[i]]),], importance = T,ntree=ntree)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
}
cat('BFS EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('BFS TRAIN RMSE:' ,mean(rmse_train), "\n")
}
rmse_eval
rmse_train
tuneRF(features_bfs,data = train[c(folds[[i]]),], ntreeTry=ntree)
tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], ntreeTry=ntree)
tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
tuneRF
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
tuneRF
View(tuneRF)
View(tuneRF)
which.min(tuneRF[,2]
which.min(tuneRF[,2])
View(tuneRF)
tuneRF[,2]
name(which.min(tuneRF[,2])
)
names(which.min(tuneRF[,2]))
as.integer(names(which.min(tuneRF[,2])))
model <- randomForest(features_bfs,data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2])))
)
model <- randomForest(features_bfs,data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2]))))
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
View(tuneRF)
model <- randomForest(features_bfs,data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2]))))
as.integer(names(which.min(tuneRF[,2])))
model <- randomForest(features_bfs,data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = 7)
?randomForest
?tuneRF
subset
subset = "P1"
subset
as.simple.formula(subset,"revenue")
names(train[,-M])
which(subset==names(train[,-M]))
subset = c("P1","P5")
subset
as.simple.formula(subset,"revenue")
which(subset==names(train[,-M]))
which(subset[2]==names(train[,-M]))
which(subset[1]==names(train[,-M]))
apply(subset,FUN = which(x==names(train[,-M])))
apply(subset,FUN = {which(x==names(train[,-M]))})
apply(subset,function(x) {which(x==names(train[,-M]))})
apply(subset,1,function(x) {which(x==names(train[,-M]))})
sapply(subset,1,function(x) {which(x==names(train[,-M]))})
sapply(subset,function(x) {which(x==names(train[,-M]))})
c(sapply(subset,function(x) {which(x==names(train[,-M]))})
)
#function for feature selection evaluation on RF
evaluator_model <- function(subset)
{
cat('Current Subset:' ,subset, "\n")
ntree <- 25
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),c(sapply(subset,function(x) {which(x==names(train[,-M]))}))], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
model <- randomForest(as.simple.formula(subset,"revenue"),data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2]))))
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rm(model,prediction)
}
cat('Current mean EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('Current sd EVAL RMSE:' ,sd(rmse_eval), "\n")
cat('Current difference EVAL RMSE and TRAIN RMSE:' ,abs(mean(rmse_eval)-mean(rmse_train)), "\n")
#return(-mean(rmse_eval)) #optimize on minimum mean RMSE
#return(-sd(rmse_eval)) #optimize on minimum sd RMSE
#return(-abs(mean(rmse_eval)-mean(rmse_train))) #optimize on RMSE difference between eval and train
return(-log10(sd(rmse_eval))*log10(mean(rmse_eval))*log10(abs(mean(rmse_eval)-mean(rmse_train)))) #optimize on all metrics
}
#BFS Feature Selection only
{
subset_bfs <- NULL
subset_bfs <- best.first.search(sample(names(train[,-M])),evaluator_model)
features_bfs <- as.simple.formula(subset_bfs, "revenue")
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times)) {
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
model <- randomForest(features_bfs,data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2]))))
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
}
cat('BFS EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('BFS TRAIN RMSE:' ,mean(rmse_train), "\n")
}
unname(subset)
tmp <- unname(subset)
tmp
subset
tmp <- c(sapply(subset,function(x) {which(x==names(train[,-M]))}))
tmp
unname(tmp)
#Initialization
{
sessionInfo() #system pemodelormance
gc() #clear unsued memory
rm(list=ls()) # clear workspace
mainDir <- "C:/Users/user/Documents/R/Restaurant"
setwd(mainDir)
set.seed(1234) #setting seed for comparison
library(foreach); library(doParallel);
library(ggplot2); library(randomForest);
library(lubridate); library(e1071);
library(FSelector); library(caret);
library(RCurl); library(fpp);
library(nnet);
}
#Read Data
{
train <- read.csv("train.csv")
test <- read.csv("test.csv")
Submission <- read.csv("sampleSubmission.csv")
N <- nrow(train) #Number of examples train
Ntest <- nrow(test) #Number of examples test
train <- train[,-1] #remove ID column
test <- test[,-1] #remove ID column
}
#Create a factor of all cities names (train & test) and save as integers (too many facotrs)
{
city_names <- sort(unique(c(levels(test$City),levels(train$City))))
train$City <- as.integer(factor(train$City,levels = city_names))
test$City <- as.integer(factor(test$City,levels = city_names))
}
#Create a factor of all restaurant types (train & test)
{
rest_types <- sort(unique(c(levels(test$Type),levels(train$Type))))
train$Type <- factor(train$Type,levels = rest_types)
test$Type <- factor(test$Type,levels = rest_types)
}
#Convert date field to separate columns: day, month and year (factorized)
{
train$day <- factor(day(as.POSIXlt(train$Open.Date, format="%m/%d/%Y")),levels = c(1:31))
train$month <- factor(month(as.POSIXlt(train$Open.Date, format="%m/%d/%Y")),levels = c(1:12))
train$year <- factor(year(as.POSIXlt(train$Open.Date, format="%m/%d/%Y")),levels = c(1995:2014))
test$day <- factor(day(as.POSIXlt(test$Open.Date, format="%m/%d/%Y")),levels = c(1:31))
test$month <- factor(month(as.POSIXlt(test$Open.Date, format="%m/%d/%Y")),levels = c(1:12))
test$year <- factor(year(as.POSIXlt(test$Open.Date, format="%m/%d/%Y")),levels = c(1995:2014))
train <- train[,-1] #remove Open.Date column
test <- test[,-1] #remove Open.Date colum
}
#Transform the Revenues Column - don't forget to transform back!
{
train$revenue <- log10(train$revenue)
hist(train$revenue)
revenue <- train$revenue
train <- train[,-41]
train$revenue <- revenue
}
#Divide to train and eval - multifolds & other initializations
{
K <- 3 #number of folds (70-30)
Times <- 5 #number of resamples (5)
folds <- createMultiFolds(train$revenue,k=K,times = Times)
M <- ncol(train)
ntree <- 25
rm(revenue,city_names,rest_types)
}
#function for feature selection evaluation on RF
evaluator_model <- function(subset)
{
cat('Current Subset:' ,subset, "\n")
ntree <- 25
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
predictors <- unname(c(sapply(subset,function(x) {which(x==names(train[,-M]))})))
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),predictors], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
model <- randomForest(as.simple.formula(subset,"revenue"),data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2]))))
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rm(model,prediction)
}
cat('Current mean EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('Current sd EVAL RMSE:' ,sd(rmse_eval), "\n")
cat('Current difference EVAL RMSE and TRAIN RMSE:' ,abs(mean(rmse_eval)-mean(rmse_train)), "\n")
#return(-mean(rmse_eval)) #optimize on minimum mean RMSE
#return(-sd(rmse_eval)) #optimize on minimum sd RMSE
#return(-abs(mean(rmse_eval)-mean(rmse_train))) #optimize on RMSE difference between eval and train
return(-log10(sd(rmse_eval))*log10(mean(rmse_eval))*log10(abs(mean(rmse_eval)-mean(rmse_train)))) #optimize on all metrics
}
#BFS Feature Selection only
{
subset_bfs <- NULL
subset_bfs <- best.first.search(sample(names(train[,-M])),evaluator_model)
features_bfs <- as.simple.formula(subset_bfs, "revenue")
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times)) {
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
model <- randomForest(features_bfs,data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2]))))
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
}
cat('BFS EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('BFS TRAIN RMSE:' ,mean(rmse_train), "\n")
}
predictors <- unname(c(sapply("P28",function(x) {which(x==names(train[,-M]))})))
x = train[c(folds[[i]]),predictors]
i =1
x = train[c(folds[[i]]),predictors]
rm(x)
train[c(folds[[i]]),predictors]
train[c(folds[[i]]),M]
predictors <- unname(c(sapply(subset,function(x) {which(x==names(train[,-M]))})))
subset = "P28"
predictors <- unname(c(sapply(subset,function(x) {which(x==names(train[,-M]))})))
predictors
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),predictors], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
train[c(folds[[i]]),M]
train[c(folds[[i]]),predictors]
ntree
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),predictors], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
train[c(folds[[i]]),predictors]
sample(names(train[,-M]))
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
View(tuneRF)
model <- randomForest(as.simple.formula(subset,"revenue"),data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2]))))
tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.1, ntreeTry=ntree,trace = F,plot = F)
View(tuneRF)
model <- randomForest(as.simple.formula(subset,"revenue"),data = train[c(folds[[i]]),], importance = T,ntree=ntree,mtry = as.integer(names(which.min(tuneRF[,2]))))
#function for feature selection evaluation on RF
evaluator_model <- function(subset)
{
cat('Current Subset:' ,subset, "\n")
ntree <- 25
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
#predictors <- unname(c(sapply(subset,function(x) {which(x==names(train[,-M]))}))) #the specific predictor of current subset
#tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.1, ntreeTry=ntree,trace = F,plot = F)
model <- randomForest(as.simple.formula(subset,"revenue"),data = train[c(folds[[i]]),], importance = T,ntree=ntree)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rm(model,prediction)
}
cat('Current mean EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('Current sd EVAL RMSE:' ,sd(rmse_eval), "\n")
cat('Current difference EVAL RMSE and TRAIN RMSE:' ,abs(mean(rmse_eval)-mean(rmse_train)), "\n")
#return(-mean(rmse_eval)) #optimize on minimum mean RMSE
#return(-sd(rmse_eval)) #optimize on minimum sd RMSE
#return(-abs(mean(rmse_eval)-mean(rmse_train))) #optimize on RMSE difference between eval and train
return(-log10(sd(rmse_eval))*log10(mean(rmse_eval))*log10(abs(mean(rmse_eval)-mean(rmse_train)))) #optimize on all metrics
}
rm(tuneRF,predictors,subset)
#BFS Feature Selection only
{
subset_bfs <- NULL
subset_bfs <- best.first.search(sample(names(train[,-M])),evaluator_model)
features_bfs <- as.simple.formula(subset_bfs, "revenue")
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times)) {
#tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.5, ntreeTry=ntree,trace = F,plot = F)
model <- randomForest(features_bfs,data = train[c(folds[[i]]),], importance = T,ntree=ntree)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
}
cat('BFS EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('BFS TRAIN RMSE:' ,mean(rmse_train), "\n")
}
rmse_eval
rmse_train
ntree <- 1000
#function for feature selection evaluation on RF
evaluator_model <- function(subset)
{
cat('Current Subset:' ,subset, "\n")
ntree <- 1000
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
#predictors <- unname(c(sapply(subset,function(x) {which(x==names(train[,-M]))}))) #the specific predictor of current subset
#tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.1, ntreeTry=ntree,trace = F,plot = F)
model <- randomForest(as.simple.formula(subset,"revenue"),data = train[c(folds[[i]]),], importance = T,ntree=ntree)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rm(model,prediction)
}
cat('Current mean EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('Current sd EVAL RMSE:' ,sd(rmse_eval), "\n")
cat('Current difference EVAL RMSE and TRAIN RMSE:' ,abs(mean(rmse_eval)-mean(rmse_train)), "\n")
#return(-mean(rmse_eval)) #optimize on minimum mean RMSE
#return(-sd(rmse_eval)) #optimize on minimum sd RMSE
#return(-abs(mean(rmse_eval)-mean(rmse_train))) #optimize on RMSE difference between eval and train
return(-log10(sd(rmse_eval))*log10(mean(rmse_eval))*log10(abs(mean(rmse_eval)-mean(rmse_train)))) #optimize on all metrics
}
#Backward search Feature Selection only
{
subset_bs <- NULL
subset_bs <- backward.search(sample(names(train[,-M])),evaluator_model)
features_bs <- as.simple.formula(subset_bs, "revenue")
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
model <- randomForest(features_bs,data = train[c(folds[[i]]),], importance = T,ntree=ntree)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
}
cat('BFS EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('BFS TRAIN RMSE:' ,mean(rmse_train), "\n")
}
#function for feature selection evaluation on RF
evaluator_model <- function(subset)
{
cat('Current Subset:' ,subset, "\n")
ntree <- 1000
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
#predictors <- unname(c(sapply(subset,function(x) {which(x==names(train[,-M]))}))) #the specific predictor of current subset
#tuneRF <- tuneRF(y = train[c(folds[[i]]),M],x = train[c(folds[[i]]),-M], stepFactor=1.1, ntreeTry=ntree,trace = F,plot = F)
model <- randomForest(as.simple.formula(subset,"revenue"),data = train[c(folds[[i]]),], importance = T,ntree=ntree)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
rm(model,prediction)
}
cat('Current mean EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('Current sd EVAL RMSE:' ,sd(rmse_eval), "\n")
cat('Current difference EVAL RMSE and TRAIN RMSE:' ,abs(mean(rmse_eval)-mean(rmse_train)), "\n")
#return(-mean(rmse_eval)) #optimize on minimum mean RMSE
#return(-sd(rmse_eval)) #optimize on minimum sd RMSE
#return(-abs(mean(rmse_eval-rmse_train))) #optimize on RMSE difference between eval and train
return(-log10(sd(rmse_eval))*log10(mean(rmse_eval))*log10(abs(mean(rmse_eval-rmse_train)))) #optimize on all metrics
}
#Backward search Feature Selection only
{
subset_bs <- NULL
subset_bs <- backward.search(sample(names(train[,-M])),evaluator_model)
features_bs <- as.simple.formula(subset_bs, "revenue")
rmse_train <- rep(0,(K*Times))
rmse_eval <- rep(0,(K*Times))
for (i in 1:(K*Times))
{
model <- randomForest(features_bs,data = train[c(folds[[i]]),], importance = T,ntree=ntree)
#varImpPlot(model)
prediction <- predict(model,train[c(folds[[i]]),-M])
rmse_train[i] <- sqrt(mean((10^train$revenue[c(folds[[i]])]-10^prediction)^2))
prediction <- predict(model,train[-c(folds[[i]]),-M])
rmse_eval[i] <- sqrt(mean((10^train$revenue[-c(folds[[i]])]-10^prediction)^2))
}
cat('BFS EVAL RMSE:' ,mean(rmse_eval), "\n")
cat('BFS TRAIN RMSE:' ,mean(rmse_train), "\n")
}
rmse_train
rmse_eval
features_bs

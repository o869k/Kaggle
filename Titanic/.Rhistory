pb <- pbeta(0.75)
pb <- pbeta(0.75,1)
pb <- pbeta(0.75,2,1)
pb
?pbinom
pbinom(7,8,0.5)
pbinom(6,8,0.5)
pbinom(7,8,0.5,lowr.tail=FALSE)
pbinom(7,8,0.5,lower.tail=FALSE)
pbinom(6,8,0.5,lower.tail=FALSE)
pbinom(5,8,0.5,lower.tail=FALSE)
pbinom(8,8,0.5,lower.tail=FALSE)
pbinom(7,8,0.5,lower.tail=FALSE)
qnorm(0.95)
ppois(40,9*5)
?sample
sample(0:1,1000)
sample(0:1,1000,replace=TRUE)
sample(0:1,1000,replace=TRUE)/(1:n)
sample(0:1,1000,replace=TRUE)/(1:1000)
cumsum(sample(0:1,1000,replace=TRUE))/(1:1000)
plot(cumsum(sample(0:1,1000,replace=TRUE))/(1:1000))
library(UsingR)
download.packages(UsingR)
download.packages("UsingR")
download.packages(date)
download.packages("date"")
download.packages("date")
setwd("~/")
download.packages("date")
file.info(x)
file.info(
)
install.packages(c("labeling", "psych"))
download.packages("date")
?destdir
?destdir()
?file.info(x)
download.packages("date.R")
download.packages("date.R",destdir=C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages)
download.packages("date.R",destdir="C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages")
download.packages(date.R,destdir="C:\Users\user\AppData\Local\Temp\RtmporU4ma\downloaded_packages")
download.packages("date.R",destdir="C:/Users\user\AppData/Local/Temp/RtmporU4ma/downloaded_packages")
download.packages("date.R",destdir="/Users\user\AppData/Local/Temp/RtmporU4ma/downloaded_packages")
download.packages("date.R",destdir=.)
download.packages("date.R",destdir=NULL)
download.packages(date.R,destdir=NULL)
download.packages(date.R)
library("ggplot2", lib.loc="~/R/win-library/3.1")
install.packages("date")
install.packages(UsingR)
install.packages("UsingR")
data(fater.son)
library(UsingR)
data(father.son)
View(father.son)
summary(father.son)
x <- father.son$sheight
mean(x)
mean(x)+c(-1,1)*qnorm(0.975)*sd(x)/sqrt(length(x))
mean(x)+c(-1,1)*qnorm(0.95)*sd(x)/sqrt(length(x))
x <- father.son$fheight
mean(x)+c(-1,1)*qnorm(0.95)*sd(x)/sqrt(length(x))
poisson.test(10)
poisson.test(10)$conf
poisson.test(10,T = 1)$conf
poisson.test(60,T = 1)$conf
poisson.test(10,T = 60)$conf
poisson.test(10,T = 1)$conf
poisson.test(0.1,T = 1)$conf
poisson.test(6,T = 1)$conf
poisson.test(10,T = 10)$conf
poisson.test(10,T = 60)$conf
poisson.test(10,T = 6)$conf
poisson.test(10,T = 3)$conf
poisson.test(10,T = 2)$conf
poisson.test(10,T = 1)$conf
poisson.test(20,T = 1)$conf
poisson.test(5,T = 1)$conf
install.packages(ISLR)
install.packages("ISLR")
library("ggplot2", lib.loc="~/R/win-library/3.1")
library(ISLR); library(ggplot2)
data(Wage)
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- spam[inTrain,]
testSet <- spam[-inTrain,]
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
library("caret") # a ML models package
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
featurePlot(x=trainSet[,c("age","jobclass")],y=trainSet$wage,plot="pairs") #present the wage date vs. age & jobclass
qplot(wage,color=eductaion,data=trainSet,geom="density") # a density plot of wage vs. education
qplot(wage,color=education,data=trainSet,geom="density") # a density plot of wage vs. education
library(kernlab); library("e1071"); data(spam)
library(kernlab); library("e1071"); data(spam)
inTrain <- createDataPartition(y=spam$type,p=0.75,list=F) #create 75% train set of data
trainSet <- spam[inTrain,]
testSet <- spam[-inTrain,]
folds1 <- createFolds(y=trainSet$type,k=10,list=TRUE,returnTrain = TRUE)#create a 10 kfold cross validation on train set for features optimization
folds2 <- createResample(y=spam$type,times=10,list=TRUE)#create a 10 kfold resampling on data with replacement
#sapply(folds1,length) #size of folds
modelFit <- train(type ~ .,data=trainSet,method="glm") #train a glm algo on data
modelFit$finalModel #best fitted model
predictions <- predict(modelFit,newdata=testSet) #run the fitted model on test data
confusionMatrix(predictions,testSet$type) #creates a hypotesis tableconfusion matrix
#Standardizing the features
preObj <- preProcess(trainSet[,-58],method==c("center","scale"))
trainSetStandart <- predict(preObj,trainSet[,-58])$capitalAAve
preObj <- preProcess(trainSet[,-58],method=c("center","scale"))
trainSetStandart <- predict(preObj,trainSet[,-58])$capitalAAve
preObj <- preProcess(trainSet[,-58],method=c("center","scale","knnImpute"))
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=F) #create 75% train set of data
trainSet <- Wage[inTrain,]
testSet <- Wage[-inTrain,]
dummies <- dummyVars(wage ~ jobclass,data=trainSet)
head(dummies)
head(dummies,newdata=trainSet)
head(predict(dummies,newdata=trainSet))
nsv <- nearZeroVar(trainSet,saveMetrics = T) #check for zero covariates
nsv
#Initialization
{
sessionInfo() #system performance
gc() #clear unsued memory
rm(list=ls()) # clear workspace
setwd("C:/Users/user/Documents/R/Titanic")
set.seed(1234) #setting seed for comparison
library(rpart); library(rattle)
library(date); library(fpp)
library(ff); library(ggplot2)
library(rpart.plot); library(RColorBrewer)
library(e1071); library(UsingR)
library(randomForest); library(caret)
library(party); library(car)
}
#Read Data
{
trainSet <- read.csv("train.csv")
testSet <- read.csv("test.csv")
testSet$Survived <- rep(0,418)
}
###Pre Processing###
#Add an indication of a child (they mostly survived)
{
trainSet$Child <- 0
trainSet$Child[trainSet$Age < 18] <- 1
testSet$Child <- 0
testSet$Child[testSet$Age < 18] <- 1
}
#Imputation: Fix the empty embarkments & fares (must be in order for predict to work)
{
trainSet$Embarked[which(trainSet$Embarked=="")] <- "S"
trainSet$Embarked <- factor(trainSet$Embarked) # don't forget to reFactorize
testSet$Embarked[which(testSet$Embarked=="")] <- "S"
testSet$Embarked <- factor(testSet$Embarked) # don't forget to reFactorize
trainSet$Fare[which(is.na(trainSet$Fare))] <- median(trainSet$Fare,na.rm = TRUE)
testSet$Fare[which(is.na(testSet$Fare))] <- median(testSet$Fare,na.rm = TRUE)
}
#Categorized the fares to 5 equal groups
{
trainSet$Fare2 <- "70+"
trainSet$Fare2[trainSet$Fare<70 & trainSet$Fare>=30] <- "30-70"
trainSet$Fare2[trainSet$Fare<30 & trainSet$Fare>=20] <- "20-30"
trainSet$Fare2[trainSet$Fare<20 & trainSet$Fare>=10] <- "10-30"
trainSet$Fare2[trainSet$Fare<10 & trainSet$Fare>=7.8] <- "7.8-10"
trainSet$Fare2[trainSet$Fare<7.8] <- "-7.8"
trainSet$Fare2 <- factor(trainSet$Fare2)
testSet$Fare2 <- "70+"
testSet$Fare2[testSet$Fare<70 & testSet$Fare>=30] <- "30-70"
testSet$Fare2[testSet$Fare<30 & testSet$Fare>=20] <- "20-30"
testSet$Fare2[testSet$Fare<20 & testSet$Fare>=10] <- "10-30"
testSet$Fare2[testSet$Fare<10 & testSet$Fare>=7.8] <- "7.8-10"
testSet$Fare2[testSet$Fare<7.8] <- "-7.8"
testSet$Fare2 <- factor(testSet$Fare2)
}
#Categorized the title of passangers to 8 groups
{
trainSet$Title <- sapply(trainSet$Name , FUN=function(x) {strsplit(as.character(x), split='[,.]')[[1]][2]})
testSet$Title <- sapply(testSet$Name , FUN=function(x) {strsplit(as.character(x), split='[,.]')[[1]][2]})
trainSet$Title[trainSet$Title %in% c(' Capt', ' Col', ' Don', ' Major', ' Sir')] <- 'Sir'
testSet$Title[testSet$Title %in% c(' Capt', ' Col', ' Don', ' Major', ' Sir')] <- 'Sir'
trainSet$Title[trainSet$Title %in% c(' Dona', ' Lady', ' the Countess', ' Jonkheer')] <- 'Lady'
testSet$Title[testSet$Title %in% c(' Dona', ' Lady', ' the Countess', ' Jonkheer')] <- 'Lady'
trainSet$Title[trainSet$Title %in% c(' Mme', ' Mlle')] <- ' Mrs'
testSet$Title[testSet$Title %in% c(' Mme', ' Mlle')] <- ' Mrs'
trainSet$Title[trainSet$Title %in% c(' Ms')] <- ' Miss'
testSet$Title[testSet$Title %in% c(' Ms')] <- ' Miss'
trainSet$Title <- factor(trainSet$Title)
testSet$Title <- factor(testSet$Title)
}
#Imputation: Fix the age NA by a decision tree (mustn't be NA's in order for predict to work)
{
AgefitTrain <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare2 + Embarked + Child + Title ,data=trainSet[!is.na(trainSet$Age),], method="anova")
AgefitTest <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare2 + Embarked + Child + Title ,data=testSet[!is.na(trainSet$Age),], method="anova")
trainSet$Age[(is.na(trainSet$Age))] <- predict(AgefitTrain,trainSet[(is.na(trainSet$Age)),])
testSet$Age[(is.na(testSet$Age))] <- predict(AgefitTest,testSet[(is.na(testSet$Age)),])
}
###Training###
#Create Cross Validation
{
Folds <- 3
trainSetInd <- createFolds(trainSet$Survived,Folds,list=T,returnTrain=T)
sapply(trainSetInd,length) #size of folds
}
#Run for each model & evaluate
{
Err <- rep(0,9)
for (i in 1:Folds)
{
#Random Forest - option I
{
RFfit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],], importance=TRUE, ntree=2000)
varImpPlot(RFfit)
Survived <- predict(RFfit,trainSet[-trainSetInd[[i]],])
Err[1] <- Err[1]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
#Random Forest - option II
{
RFfit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],], controls=cforest_unbiased(ntree=2000, mtry=3))
Survived <- predict(RFfit,trainSet[-trainSetInd[[i]],],OOB=TRUE,type = "response")
Err[2] <- Err[2]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
#Random Forest - option III
{
RFfit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],],method="rf",ntrees=2000)
Survived <- predict(RFfit,newdata=trainSet[-trainSetInd[[i]],])
Err[3] <- Err[3]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
#Boosting of trees - option IV
{
RFfit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],],method="gbm",verbose=F)
Survived <- predict(RFfit,newdata=trainSet[-trainSetInd[[i]],])
Err[4] <- Err[4]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
#NaiveBayes - option V
{
RFfit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],],method="nb")
Survived <- predict(RFfit,newdata=trainSet[-trainSetInd[[i]],])
Err[5] <- Err[5]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
#Adaboost - option VI
{
RFfit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],],method="ada")
Survived <- predict(RFfit,newdata=trainSet[-trainSetInd[[i]],])
Err[6] <- Err[6]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
#GLM - option VII
{
RFfit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],],method="glm")
Survived <- predict(RFfit,newdata=trainSet[-trainSetInd[[i]],])
Err[7] <- Err[7]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
#KNN - option VIII
{
RFfit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],],method="knn")
Survived <- predict(RFfit,newdata=trainSet[-trainSetInd[[i]],])
Err[8] <- Err[8]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
#SVM - option VII
{
RFfit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare2 + Embarked + Child + Title, data=trainSet[trainSetInd[[i]],],method="svmRadial")
Survived <- predict(RFfit,newdata=trainSet[-trainSetInd[[i]],])
Err[9] <- Err[9]+round(mean(abs((as.numeric(Survived)-1)-trainSet$Survived[-trainSetInd[[i]]])),digits=3)
}
}
mean(Err)
}
Err
ן
i
